{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait as W\n",
    "from selenium.webdriver.support import expected_conditions as E\n",
    "from selenium.webdriver import ActionChains\n",
    "import time\n",
    "import openpyxl\n",
    "\n",
    "#start chrome\n",
    "options = webdriver.ChromeOptions() \n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--ignore-ssl-errors')\n",
    "driver = webdriver.Chrome(options=options, executable_path=r'c:\\Users\\Chan Kin Yan\\Desktop\\ZOE\\BUSI\\ISOM\\ISOM3400\\project\\chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "driver.get(\"https://www.openrice.com/en/hongkong/restaurants\")\n",
    "url_main = 'https://www.openrice.com'\n",
    "url_district = ['Yuen Long','Tsuen Wan','Causeway Bay','Mong Kok','Central','Tsim Sha Tsui']\n",
    "jap = 0\n",
    "\n",
    "#creat an excel file\n",
    "path = 'restaurant_MOREinfo_6Districts.xlsx'\n",
    "wb = openpyxl.Workbook(); \n",
    "sheet = wb.active; sheet.title = \"restaurant_info\"\n",
    "sheet.append(['name', 'price', 'bookmark', 'happy', 'sad', 'food_type','location',\n",
    "                'num_branch', 'num_seat', 'pay_list', 'other_facility',\n",
    "                'taste','decor','service','hygiene','value','overall'])\n",
    "wb.save(path)\n",
    "\n",
    "#function for sending data to the created workbook\n",
    "def excel(info_list):\n",
    "    wb = openpyxl.load_workbook(path)\n",
    "    sheet = wb.active\n",
    "    for i in info_list:\n",
    "        sheet.append(i)\n",
    "    wb.save(path)\n",
    "    print(\"open and save info\")\n",
    "\n",
    "#check duplication\n",
    "def duplicate(name_list, name):\n",
    "    if name in name_list:\n",
    "        return True\n",
    "    else: \n",
    "        name_list.append(name)\n",
    "        return False\n",
    "\n",
    "def get_num(txt):\n",
    "    return [s for s in txt if s.isdigit()]\n",
    "\n",
    "# get more info by clicking into the individual restaurant\n",
    "def get_more_info(bs_more):\n",
    "    time.sleep(2)\n",
    "    #get rating\n",
    "    try:\n",
    "        rate_list = bs_more.find_all ('div',{'class':'header-score-details-right-item'})\n",
    "        criteria = { }; total = 0\n",
    "        for rate_item in rate_list:\n",
    "            c_name = str(rate_item.find('div',{'class':'header-score-details-right-item-title'}).get_text()) \n",
    "            rate = rate_item.find_all('div')[1].attrs['class'][2]\n",
    "            rate = int(get_num(rate)[0])\n",
    "            total+=rate\n",
    "            criteria[c_name]=rate\n",
    "        criteria['overall']=total\n",
    "    except:  return None\n",
    "        \n",
    "    # get number of branches\n",
    "    try:\n",
    "        num_branch=bs_more.find('section',class_='all-branches-section').a.get_text()\n",
    "        num_branch=int(''.join(get_num(num_branch)))\n",
    "    except:\n",
    "        num_branch = 1\n",
    "\n",
    "    rest_info = bs_more.find('div',class_='left-col').find('div',class_='or-section-group pois-filter-feature')\n",
    "    # get payment method\n",
    "    pay_list = []\n",
    "    try:\n",
    "        payment = rest_info.find('div',class_=\"comma-tags\").find_all('span')\n",
    "        for pay in payment:\n",
    "            pay_list.append(str(pay.get_text()))\n",
    "        pay_list=','.join(pay_list)\n",
    "    except: pass\n",
    "\n",
    "    #get num_seat\n",
    "    try:\n",
    "        num_seat = str(rest_info.find('div',class_='content'))\n",
    "        num_seat=int(''.join(get_num(num_seat)))\n",
    "    except:  return None\n",
    "\n",
    "    # other facility\n",
    "    try:\n",
    "        rest_info = bs_more.find('div',class_='left-col').find('div',class_='or-section-group pois-filter-feature')\n",
    "        other_info = rest_info.find_all('span',class_='condition-name')\n",
    "        other_facility = []\n",
    "        for item in other_info:\n",
    "            other_facility+=item.contents\n",
    "        other_facility = ','.join(other_facility)\n",
    "    except: return None\n",
    "    '''\n",
    "    #satisfaction level\n",
    "        try:\n",
    "            satisfaction_list = bs_more.find_all('div',class_='score-div')\n",
    "            satisfaction = {}\n",
    "            score_cate = ['happy','ok','sad']\n",
    "            for i in range(3):\n",
    "                satisfaction[score_cate[i]] = satisfaction_list[i].get_text()\n",
    "        except: return None\n",
    "    '''\n",
    "    return list(criteria.values()), num_branch, pay_list, num_seat, other_facility, \n",
    "\n",
    "#get info\n",
    "def get_info(bs, district, info_list,url):\n",
    "    global name_list\n",
    "    item_list =  bs.find_all('section',class_='content-wrapper')\n",
    "    info_jap=[]\n",
    "\n",
    "    #get info of each restaurant\n",
    "    for item in item_list:\n",
    "\n",
    "        name = item.find('h2').a.string\n",
    "        #check duplication\n",
    "        if duplicate(name_list,name): continue\n",
    "        print(name)\n",
    "\n",
    "        try:\n",
    "            price = item.find('div',{'class':'icon-info icon-info-food-price'}).span.string\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            bookmark = item.find('div',{'class':'text bookmarkedUserCount js-bookmark-count'}).get(\"data-count\")\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            sad = item.find('span',{'class':'score highlight'}).string\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            happy = item.find('span',{'class':'score score-big highlight'}).string\n",
    "        except AttributeError:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            food_type = item.find('li').string\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            location = item.find('div',{'class':'icon-info address'}).a.string\n",
    "            if location != district: continue\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        #save data\n",
    "        one_res = [name, price, bookmark, happy, sad, food_type, location]\n",
    "        if 'Japan' in food_type:\n",
    "            global jap; jap+=1\n",
    "            info_jap.append(one_res)\n",
    "        else:\n",
    "            info_list.append(one_res); time.sleep(2)\n",
    "     \n",
    "    #enter new page for extra info if janpanese food\n",
    "    for i in range(len(info_jap)):\n",
    "        name_japan = info_jap[i][0]\n",
    "        try:\n",
    "            # click into the individual restaurant\n",
    "            while True:\n",
    "                try:\n",
    "                    moreinfo = W(driver,15).until(E.presence_of_element_located((By.PARTIAL_LINK_TEXT,str(name_japan))))\n",
    "                    moreinfo.click()\n",
    "                    break\n",
    "                except:\n",
    "                    driver.get(url); time.sleep(5)\n",
    "                    #driver.execute_script(\"window.history.go(-1)\"); time.sleep(5)\n",
    "\n",
    "            #getting more info of the restaurant    \n",
    "            time.sleep(2)\n",
    "            bs_more=BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            bs_more.prettify()\n",
    "            \n",
    "            try:\n",
    "                criteria, num_branch, pay_list, num_seat, other_facility = get_more_info(bs_more)\n",
    "                \n",
    "                print('getting more')\n",
    "            except: time.sleep(3) ;continue\n",
    "                \n",
    "            print('enter',name_japan)\n",
    "            # go back to the main page\n",
    "            try:\n",
    "                driver.execute_script(\"window.history.go(-1)\")\n",
    "                driver.implicitly_wait(1)\n",
    "                time.sleep(5)\n",
    "                print('go_out')\n",
    "            except:\n",
    "                print('go back failed')\n",
    "                driver.quit()\n",
    "        except:\n",
    "            print('cannot',name_japan); continue\n",
    "\n",
    "        #save the data \n",
    "        info_jap[i]+= [num_branch, num_seat, pay_list, other_facility]\n",
    "        for j in criteria:\n",
    "            info_jap[i].append(j)\n",
    "    #sava data to main info list\n",
    "    info_list+=info_jap\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "#main\n",
    "cookie_pressed = False\n",
    "name_list = []\n",
    "\n",
    "for district in url_district:\n",
    "    info_list = []\n",
    "    #find search box\n",
    "    try:\n",
    "        search_box = driver.find_element_by_name(\"where\")\n",
    "        search_box.clear() \n",
    "        search_box.send_keys(district)\n",
    "        search = driver.find_element_by_xpath('//*[@id=\"header\"]/div[2]/div[4]/div/button').click()\n",
    "        time.sleep(4)\n",
    "    except:\n",
    "        print('error'); driver.quit()\n",
    "\n",
    "    #ready to get info\n",
    "    endsearch = False; page = 1; url= driver.current_url\n",
    "    \n",
    "    while not endsearch:\n",
    "        info_list = [] \n",
    "        #cookies\n",
    "        try:\n",
    "            if (page == 1 and not cookie_pressed ):\n",
    "                print('cookie pressing')\n",
    "                cookie = W(driver, 5).until(E.presence_of_element_located((By.XPATH,'//*[@id=\"cookies-agreement\"]/div/button')))\n",
    "                type(cookie)\n",
    "                cookie.click()\n",
    "                cookie_pressed = True\n",
    "        except:\n",
    "            print(\"no cookies\")\n",
    "\n",
    "        time.sleep(5)\n",
    "        bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        bs.prettify()\n",
    "        # get infomation in this page\n",
    "        get_info(bs,district,info_list,url)\n",
    "\n",
    "        #save data in this page\n",
    "        excel(info_list)\n",
    "\n",
    "        #go to next page\n",
    "        #find the link of next page \n",
    "        time.sleep(3)\n",
    "        next_page = bs.find('section', {'class':'js-pois-pagination pull-right'}).find('a',class_='pagination-button next js-next')      \n",
    "        if next_page == None:\n",
    "            endsearch = True\n",
    "        else:\n",
    "            next_page = next_page.attrs['href']\n",
    "            url=url_main+str(next_page)\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "            \n",
    "    print('done',district)\n",
    "\n",
    "driver.quit()\n",
    "print(jap) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
