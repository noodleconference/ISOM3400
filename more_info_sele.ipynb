{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait as W\n",
    "from selenium.webdriver.support import expected_conditions as E\n",
    "from selenium.webdriver import ActionChains\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function to manipulate raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check duplication of restaurant \n",
    "def duplicate(name_list, name):\n",
    "    if name in name_list:\n",
    "        return True\n",
    "    else: \n",
    "        name_list.append(name)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting number from a string\n",
    "def get_num(txt):\n",
    "    return [s for s in txt if s.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare panda data\n",
    "mainframe = pd.DataFrame({'name':[],'price':[],'bookmark':[],'happy':[],'ok':[],'sad':[],\n",
    "                        'food_type':[],'location':[],'branch':[], 'number_seat':[], 'payment':[],\n",
    "                        'overall':[],'taste':[],'decor':[],'service':[],'hygiene':[],'value':[]})\n",
    "def panda_data(oneres):\n",
    "    addrow = pd.DataFrame([oneres],columns=['name','price','bookmark','happy','ok','sad','food_type','location',\n",
    "                                            'branch', 'number_seat', 'payment',\n",
    "                                            'overall','taste','decor','service','hygiene','value']) #adding additional row\n",
    "    global mainframe\n",
    "    mainframe=mainframe.append(addrow,ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function for getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get more info by clicking into the individual restaurant\n",
    "def get_more_info(bs_more):\n",
    "    time.sleep(3)\n",
    "\n",
    "    #get rating\n",
    "    try:\n",
    "        rate_list = bs_more.find_all ('div',{'class':'header-score-details-right-item'})\n",
    "        overall = bs_more.find('div',class_='header-score').get_text()\n",
    "        criteria = {'overall': overall}\n",
    "        for rate_item in rate_list:\n",
    "            c_name = str(rate_item.find('div',{'class':'header-score-details-right-item-title'}).get_text()) \n",
    "            rate = rate_item.find_all('div')[1].attrs['class'][2]\n",
    "            rate = str(get_num(rate)[0])\n",
    "            criteria[c_name]=rate\n",
    "    except:  return None\n",
    "        \n",
    "    # get number of branches\n",
    "    try:\n",
    "        num_branch=bs_more.find('section',class_='all-branches-section').a.get_text()\n",
    "        num_branch = get_num(num_branch)\n",
    "    except:\n",
    "        num_branch = 1\n",
    "\n",
    "    rest_info = bs_more.find('div',class_='left-col').find('div',class_='or-section-group pois-filter-feature')\n",
    "    # get payment method\n",
    "    pay_list = []\n",
    "    try:\n",
    "        payment = rest_info.find('div',class_=\"comma-tags\").find_all('span')\n",
    "        for pay in payment:\n",
    "            pay_list.append(str(pay.get_text()))\n",
    "    except: pass\n",
    "\n",
    "    #get num_seat\n",
    "    try:\n",
    "        num_seat = str(rest_info.find('div',class_='content'))\n",
    "        num_seat=str(''.join(get_num(num_seat)))\n",
    "    except:  return None\n",
    "\n",
    "    # other facility\n",
    "    try:\n",
    "        rest_info = bs_more.find('div',class_='left-col').find('div',class_='or-section-group pois-filter-feature')\n",
    "        other_info = rest_info.find_all('span',class_='condition-name')\n",
    "        other_facility = []\n",
    "        for item in other_info:\n",
    "            other_facility+=item.contents\n",
    "    except: return None\n",
    "\n",
    "    #satisfaction level\n",
    "    try:\n",
    "        satisfaction_list = bs_more.find_all('div',class_='score-div')\n",
    "        satisfaction = {}\n",
    "        score_cate = ['happy','ok','sad']\n",
    "        for i in range(3):\n",
    "            satisfaction[score_cate[i]] = satisfaction_list[i].get_text()\n",
    "    except: return None\n",
    "\n",
    "    return list(criteria.values()), num_branch, pay_list, num_seat, other_facility, satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get info for each district\n",
    "def get_info(bs, district):\n",
    "    global name_list\n",
    "    item_list =  bs.find_all('section',class_='content-wrapper')\n",
    "\n",
    "    #get info of each restaurant\n",
    "    for item in item_list:\n",
    "        name = item.find('h2').a.string\n",
    "        \n",
    "        #enter new page for extra info\n",
    "        try:\n",
    "            moreinfo = W(driver, 5).until(E.presence_of_element_located((By.LINK_TEXT,str(name))))\n",
    "            moreinfo.click()\n",
    "            time.sleep(5)\n",
    "            bs_more=BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            bs_more.prettify()\n",
    "            try:\n",
    "                criteria, num_branch, pay_list, num_seat, other_facility, satisfaction = get_more_info(bs_more)\n",
    "            except: continue\n",
    "            print('enter',name)\n",
    "\n",
    "            try:\n",
    "                driver.execute_script(\"window.history.go(-1)\")\n",
    "                print('go_out')\n",
    "            except:\n",
    "                print('go back failed')\n",
    "                driver.quit()\n",
    "        except:\n",
    "            print('cannot',name); continue\n",
    "        \n",
    "        #go back main page get info \n",
    "        try:\n",
    "            price = item.find('div',{'class':'icon-info icon-info-food-price'}).span.string\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            bookmark = item.find('div',{'class':'text bookmarkedUserCount js-bookmark-count'}).get(\"data-count\")\n",
    "        except AttributeError:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            food_type = item.find('li').string\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            location = item.find('div',{'class':'icon-info address'}).a.string\n",
    "            if location != district: continue\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        #check duplication and add to the pandaframe\n",
    "        if not duplicate(name_list,name):\n",
    "            one_res = [name, price, bookmark,\n",
    "                        satisfaction['happy'], satisfaction['ok'], satisfaction['sad'],\n",
    "                        food_type,location, num_branch, num_seat,pay_list]\n",
    "            for i in criteria:\n",
    "                one_res.append(i)\n",
    "            panda_data(one_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare url for searching other district\n",
    "url_main = 'https://www.openrice.com'\n",
    "url_district = ['Causeway Bay','Mong Kok','Central','Tsim Sha Tsui','Yuen Long','Tsuen Wan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start chrome\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.openrice.com/en/hongkong/restaurants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cookie pressing\n",
      "enter Mamaday\n",
      "go_out\n",
      "cannot Dodam Chicken (利舞臺廣場)\n",
      "cannot Little Vegas\n",
      "cannot Sodam Chicken\n",
      "cannot The Grill Room (The L. Square)\n",
      "cannot Kobekyu (Bartlock Centre) 吉列牛忌廉烏冬專門店 (百樂中心)\n",
      "cannot Tsukiji Japanese Restaurant (Island Beverley) 築地日本料理 (金百利廣場)\n",
      "cannot Bingo & Cook\n",
      "cannot Toretore Hamayaki 漁獲浜燒\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "cookie_pressed = False\n",
    "name_list = []\n",
    "for district in url_district:\n",
    "    #find search box\n",
    "    try:\n",
    "        search_box = driver.find_element_by_name(\"where\")\n",
    "        search_box.clear() \n",
    "        search_box.send_keys(district)\n",
    "        search = driver.find_element_by_xpath('//*[@id=\"header\"]/div[2]/div[4]/div/button').click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        print('error'); driver.quit()\n",
    "\n",
    "    #ready to get info\n",
    "    endsearch = False; page = 1; info_list = []\n",
    "    \n",
    "    while not endsearch:\n",
    "        #cookies\n",
    "        try:\n",
    "            if (page == 1 and not cookie_pressed ):\n",
    "                print('cookie pressing')\n",
    "                cookie = W(driver, 2).until(E.presence_of_element_located((By.XPATH,'//*[@id=\"cookies-agreement\"]/div/button')))\n",
    "                type(cookie)\n",
    "                cookie.click()\n",
    "                cookie_pressed = True\n",
    "                #driver.implicitly_wait(5)\n",
    "        except:\n",
    "            print(\"no cookies\")\n",
    "\n",
    "        bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        bs.prettify()\n",
    "        time.sleep(2)\n",
    "        get_info(bs,district)\n",
    "       \n",
    "        #go to next page\n",
    "        # find the link of next page \n",
    "        try:\n",
    "            nextpage = W(driver, 5).until(E.presence_of_element_located((By.LINK_TEXT,str(page))))\n",
    "            #actions = ActionChains(driver)\n",
    "            #actions.move_to_element(nextpage)\n",
    "        except:\n",
    "            endsearch = True\n",
    "            break\n",
    "       #click on next page\n",
    "        if not nextpage:\n",
    "            endsearch = True\n",
    "        else:\n",
    "            print(page)\n",
    "            page +=1\n",
    "            nextpage.click()\n",
    "            #actions.click(on_element=nextpage).perform()\n",
    "            time.sleep(5)\n",
    "\n",
    "    print('done',district)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "#dataframe to csv\n",
    "\n",
    "mainframe.to_csv('restaurant_info_6Districts.csv',sheet_name='restaurant info')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
